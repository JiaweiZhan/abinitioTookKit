# This file is used to cluster material based on criteria:
# 1. location to three closet atoms
# 2. density
# 3. potentially can use segmentation method from CV 
#   (Maximum Minimal Cut based on similarities between pixels)
from mpi4py import MPI
import argparse
from functools import partial
import signal
import pickle
from tqdm import tqdm
import numpy as np
import shutil, os, sys
from sklearn.cluster import KMeans

from abinitioToolKit import qbox_io, qe_io
from abinitioToolKit import utils

comm = MPI.COMM_WORLD

if __name__ == "__main__":
    signal.signal(signal.SIGINT, partial(utils.handler, comm))

    rank = comm.Get_rank()
    size = comm.Get_size()
    if rank == 0:
        utils.time_now()

    parser = argparse.ArgumentParser()
    parser.add_argument("-a", "--abinitio", type=str,
            help="abinitio software: qe/qbox. Default: qbox")
    parser.add_argument("-s", "--saveFileFolder", type=str,
            help="*.save folder generated by QE or the folder that store qbox output. Default: ../")
    args = parser.parse_args()

    if not args.abinitio:
        args.abinitio = "qbox"
    if not args.saveFileFolder:
        args.saveFileFolder = "../" 

    conf_tab = {"software": args.abinitio,
                "saveFileFolder": args.saveFileFolder,
                "MPI size": comm.Get_size()}
    utils.print_conf(conf_tab)

    # ------------------------------------------- read and store wfc --------------------------------------------
    
    abinitioRead = None
    if args.abinitio.lower() == "qbox":
        abinitioRead = qbox_io.QBOXRead(comm)
    elif args.abinitio.lower() == "qe":
        abinitioRead = qe_io.QERead(comm)

    storeFolder = './wfc/'

    comm.Barrier()
    isExist = os.path.exists(storeFolder)
    if not isExist:
        if rank == 0:
            print(f"store wfc from {storeFolder}")
        abinitioRead.read(args.saveFileFolder, storeFolder=storeFolder)
    else:
        if rank == 0:
            print(f"read stored wfc from {storeFolder}")
     
    # --------------------------------------- compute IPR by states----------------------------------------
    
    # comm.Barrier()
    with open(storeFolder + '/info.pickle', 'rb') as handle:
        info_data = pickle.load(handle)

    if rank == 0:
        cell = info_data['cell']
        atompos = info_data['atompos']

        numAxis = 40
        nearestAtomNum = 11
        delta = 1e-3

        speciesTot, positionTot = [], []
        for atompos_ in atompos:
            speciesTot.append(atompos_[0])
            positionTot.append(atompos_[1:])

        positionTot = np.array(positionTot)
        speciesTot = np.array(speciesTot)
        uniqueSpecies = np.unique(speciesTot)

        # N_atom * 3
        relativePos = positionTot @ np.linalg.inv(cell)

        gridAxis = np.linspace(0.5 / (numAxis + 1), 1 - 0.5 / (numAxis + 1), numAxis)
        grid_x, grid_y, grid_z = np.zeros([numAxis, 3]), np.zeros([numAxis, 3]), np.zeros([numAxis, 3])
        grid_x[:, 0] = gridAxis
        grid_y[:, 1] = gridAxis
        grid_z[:, 2] = gridAxis
        grid = grid_x[:, None, None, :] + grid_y[None, :, None, :] + grid_z[None, None, :, :]

        distance = grid[:, :, :, None, :] - relativePos[None, None, None, :, :]
        distance = (distance + 0.5) % 1 - 0.5
        distance = distance @ cell
        distance = np.linalg.norm(distance, axis=4)
        # distance: numAxis * numAxis * numAxis * N_atom

        topAtomIndicies = np.argsort(distance, axis=3)[:, :, :, :nearestAtomNum]

        speciesSpace = np.zeros(list(topAtomIndicies.shape[:3]) + [len(uniqueSpecies)], dtype=np.float64) 
        for i in range(speciesSpace.shape[0]):
            for j in range(speciesSpace.shape[1]):
                for k in range(speciesSpace.shape[2]):
                    speciesCount = np.zeros(len(uniqueSpecies))
                    for m in range(nearestAtomNum):
                        index = np.where(uniqueSpecies == speciesTot[topAtomIndicies[i, j, k, m]])[0]
                        speciesCount[index] += 1
                        speciesSpace[i, j, k, index] += min(1.0 / 0.71, 2.0 / (distance[i, j, k, topAtomIndicies[i, j, k, m]] + delta))
                    for m, count in enumerate(speciesCount):
                        if count >= 2:
                            speciesSpace[i, j, k, m] /= count
        data = speciesSpace.reshape((-1, speciesSpace.shape[-1]))
        # Create a KMeans clustering object with K clusters
        kmeans = KMeans(n_clusters=2)
        # print(speciesSpace[1, 1, 1])
        # print(speciesSpace[1, 1, 3])
        # print(speciesSpace[1, 1, 5])
        # print(speciesSpace[1, 1, 7])
        # print(speciesSpace[1, 1, 9])

        # Fit the model to the data
        kmeans.fit(data)

        # Get the cluster assignments for each data point
        labels = kmeans.labels_
        labels = np.array(labels).reshape(speciesSpace.shape[:3])
        print(np.mean(labels, axis=(0, 1)))

    comm.Barrier()
    if rank == 0:
        shutil.rmtree(storeFolder)
